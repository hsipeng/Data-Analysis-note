# 支持向量机(SVM)

SVM 工作原理

寻找正好分离的一个超平面

* Python

乳腺癌检测

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn import metrics

warnings.filterwarnings('ignore')
%matplotlib inline
# 导入并观察数据
data = pd.read_csv('data.csv')
pd.set_option('display.max_columns', None)
print(data.columns)
print(data.head())
print(data.describe())

# 将特征字段分为三组
features_mean = list(data.columns[2:12])
features_se = list(data.columns[12:22])
deatures_worst = list(data.columns[22:32])
# 数据清洗
# 删除id列
data.drop('id', axis=1, inplace=True)
# 将标签B良性替换为0，M恶性替换为1
data['diagnosis'] = data['diagnosis'].map({'B':0, 'M':1})

# 将肿瘤诊断结果可视化
plt.figure(figsize=(8, 6))
sns.countplot(data['diagnosis'], label='Count')
# 热力图呈现feature_mean字段之间相关性
corr = data[features_mean].corr()
plt.figure(figsize=(14, 14))
sns.heatmap(corr, annot=True) # annot显示方格中数字
# 特征选择：
# 1、mean，se，worst是对同一组内容的不同度量方式，保留mean
# 2、radius_mean，perimeter_mean，area_mean三个相关属性大，保留radius_mean
# 3、compactness_mean，daconcavity_mean，concave points_mean三个相关属性大，保留compactness_mean


# 特征选择
features_remain = ['radius_mean','texture_mean', 'smoothness_mean','compactness_mean','symmetry_mean', 'fractal_dimension_mean'] 

# 抽取30%数据作为测试集，其余作为训练集
train, test = train_test_split(data, test_size=0.3)
train_X = train[features_remain]
train_y = train['diagnosis']
test_X = test[features_remain]
test_y = test['diagnosis']

# 数据标准化
train_X = StandardScaler().fit_transform(train_X)
test_X = StandardScaler().fit_transform(test_X)

# 训练svm并测试
model = svm.SVC()
model.fit(train_X, train_y)
prediction = model.predict(test_X)
# 计算准确率
print('准确率为：', metrics.accuracy_score(prediction, test_y))
```



* R

```R
# 支持向量机(SVM)

# 数据恰好有两种类别时，你可以使用SVM




data("iris")

n <- nrow(iris)
ntrain <- round(n*0.6)
set.seed(333)
tindex <- sample(n, ntrain)
train_iris <- iris[tindex,]
test_iris <- iris[-tindex,]
head(train_iris)


library(e1071)

svm1 <- svm(Species~., data=train_iris, method="C-classification",
            kernal="radial", gamma=0.1, cost=10)

summary(svm1)


svm1$SV  # 支持向量

# svm 图展示模型的支持向量、判定边界和间隔
plot(svm1, train_iris, Petal.Width ~ Petal.Length, slice=list(Sepal.Width=3,Sepal.Length=4))


## 预测

prediction <- predict(svm1, test_iris)

xtab <- table(test_iris$Species, prediction)

xtab


# 概率

(19+17+22)/nrow(test_iris)

# Number of misclassifications
train_x <- train_iris[,-5]
train_y <- train_iris[,5]
test_x <- test_iris[,-5]
test_y <- test_iris[,5]

sum(prediction!= test_y)

```

