# 神经网络

神经网络的主要结构组成

输入层、隐藏层、输出层

并且有大量的神经元连接而成，每个链接都有一个权值，通过调整权值，能够对输入样本进行分类。



基本元素

误差、偏置以及权值



神经网络的工作原理

神经网络模型属于有监督的学习，依据已有的输入数据，结合输出目标，调整并确定权值及偏置等模型参数。神经网络的每一层级都包括若干单元，一般也称作神经元，偏置θ结合加权函数f来表现神经元的活性，即通过增加或降低θ值来调节网络输入值，w用来标识上一层神经元连接下一层神经元的权值。针对于输出层的输出单元，通常实际输出和预测输出之间会存在一定的误差，需要按照极小原则不断修正模型参数，使得误差平方和达到最小。

神经网络的工作原理就是指不断调节模型参数使得神经网络达到某种收敛状态。在训练样本集中，每一组输入都会对应一组目标输出，模型则是通过纠正实际输出和目标输出间的误差大小来调节相关参数的。



实现步骤

* 输入映射输出层

* 求出误差调参数
* 权重偏置学习率





* Python

```python
# this is needed to load helper from the parent folder
import sys
sys.path.append('..')

# the rest of the imports
import helper as hlp
import pandas as pd 
import pybrain.structure as st
import pybrain.supervised.trainers as tr
import pybrain.tools.shortcuts as pb

@hlp.timeit
def fitANN(data):
    '''
        Build a neural network classifier
    '''
    # determine the number of inputs and outputs
    inputs_cnt = data['input'].shape[1]
    target_cnt = data['target'].shape[1]

    # create the classifier object
    ann = pb.buildNetwork(inputs_cnt, 
        inputs_cnt * 2, 
        target_cnt,
        hiddenclass=st.TanhLayer,
        outclass=st.SoftmaxLayer,
        bias=True
    )

    # create the trainer object
    trainer = tr.BackpropTrainer(ann, data, 
        verbose=True, batchlearning=False)

    # and train the network
    trainer.trainUntilConvergence(maxEpochs=50, verbose=True, 
        continueEpochs=3, validationProportion=0.25)

    # and return the classifier
    return ann

# the file name of the dataset
r_filename = '../../Data/Chapter03/bank_contacts.csv'

# read the data
csv_read = pd.read_csv(r_filename)

# split the data into training and testing
train_x, train_y, \
test_x,  test_y, \
labels = hlp.split_data(
    csv_read, 
    y = 'credit_application',
    x = ['n_duration','n_euribor3m','n_age','n_emp_var_rate','n_pdays','month_mar','prev_ctc_outcome_success','n_cons_price_idx','month_apr','n_cons_conf_idx']
)

# create the ANN training and testing datasets
training = hlp.prepareANNDataset((train_x, train_y))
testing  = hlp.prepareANNDataset((test_x,  test_y))

# train the model
classifier = fitANN(training)

# classify the unseen data
predicted = classifier.activateOnDataset(testing)

# the lowest output activation gives the class
predicted = predicted.argmin(axis=1)

# print out the results
hlp.printModelSummary(test_y, predicted)
```



* R

```R
# 神经网络
# 典型包含三层（输入层，隐藏层，输出层）

# data
data("iris")

n <- nrow(iris)
ntrain <- round(n*0.6)
set.seed(333)
tindex <- sample(n, ntrain)
train_iris <- iris[tindex,]
test_iris <- iris[-tindex,]
head(train_iris)



library(neuralnet)
# 数据集转换
nn1_iristrain <- train_iris
nn1_iristrain <- cbind(nn1_iristrain, train_iris$Species=="setosa")
nn1_iristrain <- cbind(nn1_iristrain, train_iris$Species=="versicolor")
nn1_iristrain <- cbind(nn1_iristrain, train_iris$Species=="virginica")

names(nn1_iristrain)[6] <- "setosa"
names(nn1_iristrain)[7] <- "versicolor"
names(nn1_iristrain)[8] <- "virginica"
head(nn1_iristrain[,5:8])


# 构建神经网络模型
nn1 <- neuralnet(setosa+versicolor+virginica~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, 
                 data = nn1_iristrain, hidden = c(4))
print(nn1)
## 显示神经网络
plot(nn1)

## nn1 对象上使用commpute 函数, 给定一个训练好的神经网络
prediction <- compute(nn1, test_iris[-5])
prediction <- prediction$net.result

# 建立特征变量， 其中包含神经网络预测的响应变量值(Species)
# table 建立混合矩阵, 检查模型准确性

pred_idx <- function(x){return(which(x ==max(x)))}

idx <- apply(prediction, c(1), pred_idx)

prediction_nn <- c('setosa', 'versicolor', 'virginica')[idx]

xtab <- table(prediction_nn, test_iris$Species)

xtab
# 准确率
(19+16+22)/60

```

