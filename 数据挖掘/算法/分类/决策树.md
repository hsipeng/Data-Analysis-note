# 决策树



决策树基本上就是把以前的经验总结出来。



简单地说，构建决策树分类模型可以认为是一个基于机器学习等方法，从数据中获取规则和知识的过程。首先利用训练数据集生成一个决策树，训练数据一般是在一定的历史时间范围内，并且具备一定代表性的数据集。最后通过生成的决策树模型对新数据进行预测分类。

###  原理

熵的概念由美国数学家香农首先提出，主要用来度量信息，熵可以理解成信息在传播中的不确定性。实际情况中，越有序的系统，熵值就越低。越混乱的系统，熵值就越高。因此，凡是涉及系统中有序性和组织性的行为活动，都可以用熵这个概念来测量。

* 信息熵

根据香农信息量理论，把随机事件发生概率的对数负值定义为自信息量，而熵则表示为自信息量所反映随机变量的不确定性，不确定性的成分越大，或者说概率越小，熵就越大，同时也就意味着随机变量所需要的平均信息量就越大。
$$
H(X) = \sum^{n}_{i}P_iI_i=-\sum^{n}_{i}{P_ilog_a}P_i
$$

* 条件熵

信息熵的概念及度量方法也可以从单个随机变量扩展到二维随机变量。二维随机变量的条件熵H（Y|X）定义成已知随机变量X的条件下，随机变量Y的信息熵大小，即Y的平均不确定性。

根据条件概率和信息熵的定义，以及考虑到Y的各种可能取值yj，如果固定X的某一取值xi的熵H（Y|X=xi），那么条件熵H（Y|X）的值就等于随机变量X所有可能取值xi的概率Pxi及其一一对应的熵H（Y|X=xi）的加权平均，公式如上所示。


$$
H(Y|X) = \sum^{n}_{i}{P(x_i)H(Y|X=x_i)}
$$

* 信息增益

条件熵扩大了信息熵的应用范围，信息则是通过熵和条件熵之间的差值来计量的，这个差就称作信息增益。在分类系统中，信息增益是针对单个特征属性而言的，属于特征选取中的一个重要指标，是用来衡量属性价值的一个度量标准。


$$
Gain(X_i) = H(C) - H(C|X_i)
$$




### 决策树的构造

构造的过程就是选择什么属性作为节点的过程

三种节点

- 根节点
- 内部节点
- 叶节点

### 剪枝

剪枝就是给决策树瘦身

目标： 不需要太多的判断，同样可以得到不错的结果。

防止"过拟合"





## 指标

- 纯度 让目标变量的分歧最小
- 信息熵  表示了信息的不确定度





## 算法

* ID3

> 计算信息增益, 信息增益是指划分可以带来纯度的提高，信息熵的下降

* C4.5

> 对 ID3 的改进
>
> 1. 采用信息增益率
> 2. 采用悲观剪枝
> 3. 离散化处理连续属性
> 4. 处理缺失值

* CART

> CART(Classification And Regression Tree)， 中文名叫做分类回归树
>
> 
>
> ID3 和 C4.5 可以生成二叉树或多叉树
>
> CART 只支持二叉树，同时，CART 既可以做分类树，又可以作回归树
>
> ID3 信息增益
>
> C4.5 信息增益率
>
> CART 采用基尼系数选择指标





* Python

一般应用

​	 Scikit-learn

```python
# this is needed to load helper from the parent folder
import sys
sys.path.append('..')

# the rest of the imports
import helper as hlp
import pandas as pd
import sklearn.tree as sk

@hlp.timeit
def fitDecisionTree(data):
    '''
        Build a decision tree classifier
    '''
    # create the classifier object
    tree = sk.DecisionTreeClassifier(min_samples_split=1000)

    # fit the data
    return tree.fit(data[0],data[1])

# the file name of the dataset
r_filename = '../../Data/Chapter03/bank_contacts.csv'

# read the data
csv_read = pd.read_csv(r_filename)

# split the data into training and testing
train_x, train_y, \
test_x,  test_y, \
labels = hlp.split_data(
    csv_read, 
    y = 'credit_application',
    x = ['n_duration','n_nr_employed',
        'prev_ctc_outcome_success','n_euribor3m',
        'n_cons_conf_idx','n_age','month_oct',
        'n_cons_price_idx','edu_university_degree','n_pdays',
        'dow_mon','job_student','job_technician',
        'job_housemaid','edu_basic_6y']
)

# train the model
classifier = fitDecisionTree((train_x, train_y))

# classify the unseen data
predicted = classifier.predict(test_x)

# print out the results
hlp.printModelSummary(test_y, predicted)

# print out the importance of features
for counter, (nm, label) \
    in enumerate(
        zip(labels, classifier.feature_importances_)
    ):
    print("{0}. {1}: {2}".format(counter, nm,label))

# and export to a .dot file
sk.export_graphviz(classifier, 
    out_file='../../Data/Chapter03/decisionTree/tree.dot')
```



mlpy

```python
# this is needed to load helper from the parent folder
import sys
sys.path.append('..')

# the rest of the imports
import helper as hlp
import pandas as pd
import mlpy as ml

@hlp.timeit
def fitDecisionTree(data):
    '''
        Build a decision tree classifier
    '''
    # create the classifier object
    tree = ml.ClassTree(minsize=1000)

    # fit the data
    tree.learn(data[0],data[1])

    # return the classifier
    return tree

# the file name of the dataset
r_filename = '../../Data/Chapter03/bank_contacts.csv'

# read the data
csv_read = pd.read_csv(r_filename)

# split the data into training and testing
train_x, train_y, \
test_x,  test_y, \
labels = hlp.split_data(
    csv_read, 
    y = 'credit_application'
)

# train the model
classifier = fitDecisionTree((train_x, train_y))

# classify the unseen data
predicted = classifier.pred(test_x)

# print out the results
hlp.printModelSummary(test_y, predicted)
```



决策树可视化

> sk.export_graphviz(classifier, out_file='xxx.dot')
>
> .dot 文件是一个文本文件，不便于阅读
>
> 使用 GraphViz 可视化
>
> dot -Tpdf tree.dot -o tree.pdf	





### CART 回归树

```python

# CART 算法
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error,mean_squared_error
# from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import DecisionTreeRegressor
from sklearn.datasets import load_boston
from sklearn import preprocessing
from sklearn import utils

##  准备数据
boston = load_boston()

# 探索数据
print(boston.feature_names)

# 获取特征集和房价
features = boston.data
prices = boston.target

# 随机抽取 33% 的数据作为测试集，其余为训练集
train_features, test_features,train_prices, test_prices = train_test_split(features, 
                                             prices, 
                                             test_size=0.33, 
                                             random_state=24)
# 创建 CART 回归树

dtr = DecisionTreeClassifier()

# 拟合构造 CART 回归树
lab_enc = preprocessing.LabelEncoder()
# passing floats to a calssifier 可以被分类
train_prices= lab_enc.fit_transform(train_prices)
dtr.fit(train_features, train_prices)

# 预测测试集中的房价

predict_price = dtr.predict(test_features)

# 测试集的结果评价
print('回归树的二乘偏差均值:', mean_squared_error(test_prices,predict_price))
print('回归树的绝对值偏差均值:', mean_absolute_error(test_prices,predict_price))
```





### 泰坦尼克生存预测



```python
import pandas as pd
# 数据加载

train_data = pd.read_csv('./datasets/titanic/train.csv')
test_data = pd.read_csv('./datasets/titanic/test.csv')

# 1. 数据探索
print(train_data.info())
print('-'*30)
print(train_data.describe())
print('-'*30)
print(train_data.describe(include=['O']))
print('-'*30)
print(train_data.head())
print('-'*30)
print(train_data.tail())

# 2. 数据清洗
# 填充 Age nan 值
train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)
test_data['Age'].fillna(test_data['Age'].mean(), inplace=True)
# 填充 Fare nan 值
train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)
test_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)

# Cabin 大量缺失值，无法补齐


# Embarked 登陆港口
print(train_data['Embarked'].value_counts())

# 用最多的值，填充 Embarked
train_data['Embarked'].fillna('S',inplace=True)
test_data['Embarked'].fillna('S',inplace=True)

# 3. 特征选择
features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']
train_features = train_data[features]
train_labels = train_data['Survived']
test_features = test_data[features]

print(train_features.head())
print(test_features.head())

# 字符串列转换成数值
from sklearn.feature_extraction import DictVectorizer
dvec = DictVectorizer(sparse=False)
train_features= dvec.fit_transform(train_features.to_dict(orient='record'))
print(dvec.feature_names_)

# 4. 决策树模型
from sklearn.tree  import DecisionTreeClassifier
# 构造 ID3 决策树
clf = DecisionTreeClassifier(criterion='entropy')
# 决策树训练
clf.fit(train_features, train_labels)


# 5. 模型预测与评估
test_features = dvec.transform(test_features.to_dict(orient='record'))
# 决策树预测
pred_labels = clf.predict(test_features)

# 得到决策树准确率
acc_decision_tree = round(clf.score(train_features, train_labels),6)
print(u'score 准确率为 %4lf' % acc_decision_tree)



```



* R

```R
# 决策树

# data
# Play,Outlook,Temperature,Humidity,Wind
# yes,rainy,cool,normal,FALSE
# no,rainy,cool,normal,TRUE
# yes,overcast,hot,high,FALSE
# no,sunny,mild,high,FALSE
# yes,rainy,cool,normal,FALSE
# yes,sunny,cool,normal,FALSE
# yes,rainy,cool,normal,FALSE
# yes,sunny,hot,normal,FALSE
# yes,overcast,mild,high,TRUE
# no,sunny,mild,high,TRUE
library(rpart)
library(rpart.plot)

play_decision <- read.table("DTdata.csv", header=TRUE, sep=",")

play_decision

summary(play_decision)


fit <- rpart(Play ~ Outlook + Temperature + Humidity + Wind, method = "class", data=play_decision,
             control = rpart.control(minsplit = 1),
             parms = list(split="information"))


summary(fit)

# rpart.plot 可视化 summary fit
rpart.plot(fit, type = 4, extra = 1)

# 详情
rpart.plot(fit, type = 4, extra = 1, clip.right.labs = FALSE,varlen = 0,faclen = 0)

# 预测新记录

newdata <- data.frame(Outlook="rainy", Temperature="mild",
                      Humidity="high",
                      Wind=FALSE)
newdata

# 预测函数
# predict(object, newdata = list(),type=c("vector","prob","class","matrix")) 
predict(fit, newdata = newdata,type="prob")
predict(fit, newdata = newdata,type="class")

```

