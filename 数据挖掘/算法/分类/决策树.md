# 决策树



决策树基本上就是把以前的经验总结出来。



### 构造

构造的过程就是选择什么属性作为节点的过程

三种节点

- 根节点
- 内部节点
- 叶节点

### 剪枝

剪枝就是给决策树瘦身

目标： 不需要太多的判断，同样可以得到不错的结果。

防止"过拟合"





## 指标

- 纯度 让目标变量的分歧最小
- 信息熵  表示了信息的不确定度





## 算法

* ID3

> 计算信息增益, 信息增益是指划分可以带来纯度的提高，信息熵的下降

* C4.5

> 对 ID3 的改进
>
> 1. 采用信息增益率
> 2. 采用悲观剪枝
> 3. 离散化处理连续属性
> 4. 处理缺失值

* CART

> CART(Classification And Regression Tree)， 中文名叫做分类回归树
>
> 
>
> ID3 和 C4.5 可以生成二叉树或多叉树
>
> CART 只支持二叉树，同时，CART 既可以做分类树，又可以作回归树
>
> ID3 信息增益
>
> C4.5 信息增益率
>
> CART 采用基尼系数选择指标





* Python



### CART 回归树

```python

# CART 算法
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error,mean_squared_error
# from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import DecisionTreeRegressor
from sklearn.datasets import load_boston
from sklearn import preprocessing
from sklearn import utils

##  准备数据
boston = load_boston()

# 探索数据
print(boston.feature_names)

# 获取特征集和房价
features = boston.data
prices = boston.target

# 随机抽取 33% 的数据作为测试集，其余为训练集
train_features, test_features,train_prices, test_prices = train_test_split(features, 
                                             prices, 
                                             test_size=0.33, 
                                             random_state=24)
# 创建 CART 回归树

dtr = DecisionTreeClassifier()

# 拟合构造 CART 回归树
lab_enc = preprocessing.LabelEncoder()
# passing floats to a calssifier 可以被分类
train_prices= lab_enc.fit_transform(train_prices)
dtr.fit(train_features, train_prices)

# 预测测试集中的房价

predict_price = dtr.predict(test_features)

# 测试集的结果评价
print('回归树的二乘偏差均值:', mean_squared_error(test_prices,predict_price))
print('回归树的绝对值偏差均值:', mean_absolute_error(test_prices,predict_price))
```





### 泰坦尼克生存预测



```python
import pandas as pd
# 数据加载

train_data = pd.read_csv('./datasets/titanic/train.csv')
test_data = pd.read_csv('./datasets/titanic/test.csv')

# 1. 数据探索
print(train_data.info())
print('-'*30)
print(train_data.describe())
print('-'*30)
print(train_data.describe(include=['O']))
print('-'*30)
print(train_data.head())
print('-'*30)
print(train_data.tail())

# 2. 数据清洗
# 填充 Age nan 值
train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)
test_data['Age'].fillna(test_data['Age'].mean(), inplace=True)
# 填充 Fare nan 值
train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)
test_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)

# Cabin 大量缺失值，无法补齐


# Embarked 登陆港口
print(train_data['Embarked'].value_counts())

# 用最多的值，填充 Embarked
train_data['Embarked'].fillna('S',inplace=True)
test_data['Embarked'].fillna('S',inplace=True)

# 3. 特征选择
features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']
train_features = train_data[features]
train_labels = train_data['Survived']
test_features = test_data[features]

print(train_features.head())
print(test_features.head())

# 字符串列转换成数值
from sklearn.feature_extraction import DictVectorizer
dvec = DictVectorizer(sparse=False)
train_features= dvec.fit_transform(train_features.to_dict(orient='record'))
print(dvec.feature_names_)

# 4. 决策树模型
from sklearn.tree  import DecisionTreeClassifier
# 构造 ID3 决策树
clf = DecisionTreeClassifier(criterion='entropy')
# 决策树训练
clf.fit(train_features, train_labels)


# 5. 模型预测与评估
test_features = dvec.transform(test_features.to_dict(orient='record'))
# 决策树预测
pred_labels = clf.predict(test_features)

# 得到决策树准确率
acc_decision_tree = round(clf.score(train_features, train_labels),6)
print(u'score 准确率为 %4lf' % acc_decision_tree)



```



* R

```R
# 决策树

# data
# Play,Outlook,Temperature,Humidity,Wind
# yes,rainy,cool,normal,FALSE
# no,rainy,cool,normal,TRUE
# yes,overcast,hot,high,FALSE
# no,sunny,mild,high,FALSE
# yes,rainy,cool,normal,FALSE
# yes,sunny,cool,normal,FALSE
# yes,rainy,cool,normal,FALSE
# yes,sunny,hot,normal,FALSE
# yes,overcast,mild,high,TRUE
# no,sunny,mild,high,TRUE
library(rpart)
library(rpart.plot)

play_decision <- read.table("DTdata.csv", header=TRUE, sep=",")

play_decision

summary(play_decision)


fit <- rpart(Play ~ Outlook + Temperature + Humidity + Wind, method = "class", data=play_decision,
             control = rpart.control(minsplit = 1),
             parms = list(split="information"))


summary(fit)

# rpart.plot 可视化 summary fit
rpart.plot(fit, type = 4, extra = 1)

# 详情
rpart.plot(fit, type = 4, extra = 1, clip.right.labs = FALSE,varlen = 0,faclen = 0)

# 预测新记录

newdata <- data.frame(Outlook="rainy", Temperature="mild",
                      Humidity="high",
                      Wind=FALSE)
newdata

# 预测函数
# predict(object, newdata = list(),type=c("vector","prob","class","matrix")) 
predict(fit, newdata = newdata,type="prob")
predict(fit, newdata = newdata,type="class")

```

