概率论与数理统计

### 概率定义

* 样本空间、样本点

  随机试验的样本空间是试验所有可能结果组成的集合，样本空间的每个结果元素是一个样本点，不同的试验目的会生成不同的样本点。样本空间既可以是有限的，也可以是无限的。

* 事件

  * 必然事件
  * 随机事件
  * 不可能事件

* 概率

  > 虽然在某一次随机试验中，试验的结果是无法预料的，会受到偶然性支配，但是随着试验次数的逐步增大，其结果就会呈现某种规律性，因此，一般认为统计规律性是可以从实践中总结归纳出来的。

* 大数定律

  > 大数定律：大量重复试验，随机试验的频率将会在某数值附近波动，随着试验次数的增加，随机试验的频率近似于它的概率。

* 条件概率

  > 在实际情况中，有时会遇到在某一事件已经发生的情况下，求另一事件发生的概率。一般来说，对于事件A和B，条件概率P（B|A）就是在事件A发生的条件下，事件B发生的概率。

* 独立事件

  > 如果两个事件A和B互相独立，则满足P（AB）=P（A）P（B），表示其中任一事件的发生不影响另一事件的发生。

  

#### 条件概率公式

* 全概率公式

  > 当一个复杂事件与一系列互不相容的简单事件有关时，比如，若事件A的发生在不同的可能情况下，通常把此时的事件A看作某一过程的结果，B1 ，B 2，…，Bn则是这个过程的若干原因事件，且是样本空间S的一个划分，易知A=AB1+AB2+…+ABn，进一步得到P（A）=P（AB1）+P（AB2）+…+P（ABn）。
  >
  > 前面描述了通过样本划分可以把复杂事件分解为若干不相容的简单事件，这些简单事件的概率能够利用条件概率和乘法定理求得，再基于概率的可加性，得到最终复杂事件的概率值，以上即是根据全概率公式来求解的整个过程。

* 贝叶斯公式

  > 在实际应用中，有时也会需要用“结果”概率推断“原因”概率，贝叶斯公式又称后验概率公式，给出了已知P（A|B）求P（B|A）的方法。如果结果事件概率P（A）已经发生，通过贝叶斯公式则可以求出第i个原因事件的条件概率P（Bi|A）。



### 随机变量

> 随机变量是用不同的取值来表示随机试验的所有可能结果（基本事件），随机试验的结果不同，取值也会相应不同，且能够遵循的一定的统计规律。 通过引入随机变量，可以数量化随机试验，继而进一步深入研究这些变量取值的规律特点，那么也就能够从整体的角度来描述随机事件的概率分布状况。
>
> 通过引入随机变量，可以数量化随机试验，继而进一步深入研究这些变量取值的规律特点，那么也就能够从整体的角度来描述随机事件的概率分布状况。
>



* 离散

  > 离散型随机变量的取值可以看作一个数列，数列的取值是一个一个离散的自然数或整数。
  >

* 连续

  > 连续型随机变量的取值可以看作一个普通的函数，通常函数在某一区间内任意取值，且往往是连续不断的，可取无限个数值。

  > 连续型随机变量的概率分布也可以通过积分方法来研究落入某一指定区间内的概率。概率密度f（x）和分布函数F（x）互为偏导和积分关系，随机变量的概率值等于概率密度f（x）在区间内包围的曲边面积，而其在某一点上的概率等于0，即F（X=x）=P{X=x}=0。
  >

#### 正态分布

> 正态分布又名高斯分布或者常态分布，包含μ和σ两个参数。其在数学、物理等领域有着广泛的影响力和作用价值，自然界和人类社会中的很多现象都按正态分布的形式存在。
>
> 图形:
>
> 两参位置成形状，高峰最大位中央。 钟形对称分双侧，逐渐下滑匀变动。
>

* 规律

  > 正态分布的区间面积分布有一定的规律性，基于3倍标准差原理可以近似地认为正态随机变量X值几乎全部落入区间（μ-3σ,μ+3σ）内。 区间（μ-σ,μ+σ）内的面积占正态分布曲线下总面积的68％。 区间（μ-2σ,μ+2σ）内的面积占正态分布曲线下总面积的95％。

* 标准正态分布

  > 标准正态分布是正态分布的一种特殊形式，是关于y轴对称的钟形曲线。所有的正态分布都可利用标准化变换，即通过公式Z=（X-μ）/σ来转化成标准正态分布。
  >



### 数字特征

随机变量的常用特征:

数学期望、方差、协方差和相关系数

> 一般来说，通过概率分布函数，就可以全面了解随机变量的统计规律性。但有些时候，其实并不是每次都必须求出分布函数来完整描述随机变量，经常只需关注其在某些方面的重要特征即可。



* 期望

  > 数学期望反映了随机变量取值的平均程度，用E（x）表示，因此也称为均值。

* 方差

  > 方差用D（x）表示，描述了随机变量X和数学期望E（X）之间的偏离程度，是衡量随机变量X取值分散程度的一个尺度。
  >
  > 在这里，量纲是随机现象或随机变量的度量，比如距离的长短，质量的大小，速度的快慢等。量纲依据单位制确定，单位加上数值就是具体的测量数据，不同单位制下的量纲可能会不同，通常在度量之前会事先统一量纲。 

* 协方差

  > 对于多维随机变量而言，一般用协方差矩阵来表现各个变量之间的相互关系，矩阵中的每一项对应着其中任意两个变量的协方差。比如，二维随机变量（X,Y），其中D（X），D（Y），Cov（X,Y），Cov（Y,X）共同组成二维协方差矩阵。其中D（X）=Cov（X,X）。

* 相关系数

  > 协方差的取值会受到量纲的影响，为了克服这个缺点，引入了相关系数ρ。确切地说，相关系数是用来衡量随机变量之间存在的线性关系。
  >
  > 
  >
  > 当相关系数的绝对值|ρ|=1时，表示存在完全线性相关关系。其中ρ=1时，称为完全正线性相关，ρ=-1时，称为完全负线性相关。当0<|ρ|<1时，线性关系随着|ρ|的增大而逐渐增强，而随着|ρ|的减小而逐渐减弱。ρ>0表示正相关，ρ<0表示负相关，ρ=0表示不存在线性关系。

* 总体、抽样

  > 针对总体的研究主要是面向总体所对应随机变量的分布和数字特征。一般会事先从总体中抽取出部分个体作为样本来推断总体的性质。
  >
  > 样本是对总体进行统计推断的基本依据。在实际应用中，会结合不同的问题构造出不同的样本函数作为统计量来进行统计推断。



### 参数估计

如何借助样本数据来估计总体参数

点估计

区间估计



* 最小二乘法

  > 通常希望样本观测数据和曲线方程可以最好地拟合，一般会要求曲线方程的理论值与样本观测值按照某种方法使得偏差平方和达到最小，这个方法就是最小二乘法。
  >

* 极大似然估计

  > 在参数估计中，未知参数一般用θ表示，将样本的联合概率函数L看成θ的函数，用L（θ）表示，并称为样本的似然函数。在参数可能取值的范围内，找到使得似然函数L（θ）达到最大的参数值作为θ的极大似然估计值。

* 区间估计置信度

  > 一般来说，点估计得到的仅仅是未知参数的一个近似值，而此近似值的误差范围并没有实际给出，这就会缺乏一定的可信程度，而区间估计则正好弥补了这个不足。
  >
  > 在区间估计中，θ表示总体的一个未知参数，对于一个很小的正数给定值α（0<α<1），由样本确定的两个统计量θ1和θ2并满足概率P{θ1<θ<θ2}=1-α，则区间（θ1，θ2）称为θ的置信水平为1-α的置信区间。θ1和θ2分别是此置信区间的置信下限和置信上限。
  >
  > 正态总体均值μ的区间估计，首先确定统计量服从标准正态分布，经过不等式变形后，给出置信区间：
  > $$
  > (\overline{X}-\frac{\sigma}{\sqrt{n}}Z_{\alpha/2},\overline{X}+\frac{\sigma}{\sqrt{n}}Z_{\alpha/2})
  > $$
  > 这是一个以样本均值为中心的对称区间，常表示为：   
  > $$
  > \overline{X}\pm\frac{\sigma}{\sqrt{n}}Z_{\alpha/2}
  > $$
  > 



### 假设校验

统计推断

> 统计推断是从总体抽取样本，并通过对样本数据的科学分析，进而能够对总体作出合理判断。简单地说，统计推断就是由样本推断总体。
>
> 统计推断主要包括两类基本问题：
>
> 一类是前面所提到的参数估计问题，比如利用样本数据估计总体的均值或方差。
>
> 另一类就是现在正要讲述的假设检验问题，比如要回答“总体均值是否等于某一指定值”此类问题时，就需要通过样本数据结合适当的判断法则来检验此命题是否成立。

* 统计量中的假设校验

  > 接下来，提出两个对立的假设原假设H0和备则假设H1，原假设的提出应本着不轻易被拒绝的原则。 
  >
  > 
  >
  > 根据原假设所涉及到的总体特征，通常借助样本均值来判断总体均值的情况，为了衡量样本均值和μ0之间的偏差，首先构造一个检验统计量并确定其所服从的分布，构造过程主要考虑总体特征、检验参数和样本容量等实际情况，然后选取一个适当的正数k，使得通过样本数据求出的检验统计量的值大于等于k时拒绝原假设，小于k时就接受原假设。

* 弃真取伪

  > 对于两类错误，发生第一类弃真错误的可能性是能够预先知道的，而发生第二类取伪错误的可能性是预先不知道的。
  >
  > 一般来说，固定样本容量，增大弃真错误的概率可以减小发生取伪错误的概率，但是想同时减小两类错误是无法实现的。

* 显著校验小概率

  > 由于假设检验是依据样本数据作出推断，结论判断往往不能绝对化，所以发生第一类弃真错误的可能性一直都是会存在的，且无法消除。
  >
  > 然而，在实际推断的过程中，通常会希望这类错误的发生是一个小概率事件，继而也就可以认为如果原假设H0为真，拒绝H0几乎是不可能发生的。即满足概率P{拒绝H0|H0为真}<=α。

* 拒绝域

  > 给定显著性水平α，并且在已知总体方差，原假设H0的情况下，构造检验统计量。当H0为真时，服从标准正态分布N（0,1），此时设定第一类弃真错误的事件（H0为真时拒绝H0）发生的概率值为α，依据标准正态分布分位点的定义可以得出k=Zα/2
  >
  > Zα/2和-Zα/2是根据分布表查出来的分位点。如果检验统计量的值大于Zα/2或小于-Zα/2时，表明落入拒绝域内，根据小概率原理拒绝原假设，反之则接受原假设。

* Z校验

  > 已知总体方差，验证总体均值是否等于某一期望值，通常把这种检验方法称为Z检验。
  >

























